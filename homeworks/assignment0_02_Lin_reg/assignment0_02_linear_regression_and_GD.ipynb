{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VqEpGyyyGE1Z",
    "tags": [
     "pdf-title"
    ]
   },
   "source": [
    "## Solving the linear regression problem with gradient descent\n",
    "\n",
    "Today we rewise the linear regression algorithm and it's gradient solution.\n",
    "\n",
    "Your main goal will be to __derive and implement the gradient of MSE, MAE, L1 and L2 regularization terms__ respectively in general __vector form__ (when both single observation $\\mathbf{x}_i$ and corresponding target value $\\mathbf{y}_i$ are vectors).\n",
    "\n",
    "This techniques will be useful later in Deep Learning module of our course as well.\n",
    "\n",
    "We will work with [Boston housing prices dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html) subset, which have been preprocessed for your convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIf you are using Google Colab, uncomment the next lines to download `loss_and_derivatives.py` and `boston_subset.json`\\nYou can open and change downloaded `.py` files in Colab using the \"Files\" sidebar on the left.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "If you are using Google Colab, uncomment the next lines to download `loss_and_derivatives.py` and `boston_subset.json`\n",
    "You can open and change downloaded `.py` files in Colab using the \"Files\" sidebar on the left.\n",
    "'''\n",
    "# !wget https://raw.githubusercontent.com/girafe-ai/ml-mipt/basic_f20/homeworks_basic/assignment0_02_Lin_reg/loss_and_derivatives.py\n",
    "# !wget https://raw.githubusercontent.com/girafe-ai/ml-mipt/basic_f20/homeworks_basic/assignment0_02_Lin_reg/boston_subset.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8lQUR89nGE1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Run some setup code for this notebook.\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OGf3ShTNGE1q"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('boston_subset.json', 'r') as iofile:\n",
    "    dataset = json.load(iofile)\n",
    "feature_matrix = np.array(dataset['data'])\n",
    "targets = np.array(dataset['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BIUU1cOZGE10"
   },
   "source": [
    "## Warming up: matrix differentiation\n",
    "_You will meet these questions later in Labs as well, so we highly recommend to answer them right here._\n",
    "\n",
    "Credits: this theoretical part is copied from [YSDA Practical_DL course](https://github.com/yandexdataschool/Practical_DL/tree/spring2019/homework01) homework01."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CvrZt_xNGE12"
   },
   "source": [
    "Since it easy to google every task please please please try to understand what's going on. The \"just answer\" thing will not be  counted, make sure to present derivation of your solution. It is absolutely OK if you will find an answer on web then just exercise in $\\LaTeX$ copying it into here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ty4m156yGE15"
   },
   "source": [
    "Useful links: \n",
    "[1](http://www.machinelearning.ru/wiki/images/2/2a/Matrix-Gauss.pdf)\n",
    "[2](http://www.atmos.washington.edu/~dennis/MatrixCalculus.pdf)\n",
    "[3](http://cal.cs.illinois.edu/~johannes/research/matrix%20calculus.pdf)\n",
    "[4](http://research.microsoft.com/en-us/um/people/cmbishop/prml/index.htm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k8StFOCFGE17"
   },
   "source": [
    "#### Inline question 1\n",
    "$$  \n",
    "y = x^Tx,  \\quad x \\in \\mathbb{R}^N \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{dy}{dx} = \n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qtnNCP4JGE19"
   },
   "source": [
    "#### Inline question 2\n",
    "$$ y = tr(AB) \\quad A,B \\in \\mathbb{R}^{N \\times N} $$ \n",
    "\n",
    "$$\n",
    "\\frac{dy}{dA} =\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JWfcC7_dGE2A"
   },
   "source": [
    "#### Inline question 3\n",
    "$$  \n",
    "y = x^TAc , \\quad A\\in \\mathbb{R}^{N \\times N}, x\\in \\mathbb{R}^{N}, c\\in \\mathbb{R}^{N} \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{dy}{dx} =\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{dy}{dA} =\n",
    "$$\n",
    "\n",
    "Hint for the latter (one of the ways): use *ex. 2* result and the fact \n",
    "$$\n",
    "tr(ABC) = tr (CAB)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WbBc_5FhGE2B"
   },
   "source": [
    "## Loss functions and derivatives implementation\n",
    "You will need to implement the methods from `loss_and_derivatives.py` to go further.\n",
    "__In this assignment we ignore the bias term__, so the linear model takes simple form of \n",
    "$$\n",
    "\\hat{\\mathbf{y}} = XW\n",
    "$$\n",
    "where no extra column of 1s is added to the $X$ matrix.\n",
    "\n",
    "Implement the loss functions, regularization terms and their derivatives with reference to (w.r.t.) weight matrix. \n",
    "\n",
    "__Once again, you can assume that linear model is not required for bias term for now. The dataset is preprocessed for this case.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l-CX9dTLGE1y"
   },
   "source": [
    "Autoreload is a great stuff, but sometimes it does not work as intended. The code below aims to fix that. __Do not forget to save your changes in the `.py` file before reloading the desired functions.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dtELlRTOGE2E",
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [],
   "source": [
    "# This dirty hack might help if the autoreload has failed for some reason\n",
    "try:\n",
    "    del LossAndDerivatives\n",
    "except:\n",
    "    pass\n",
    "\n",
    "from loss_and_derivatives import LossAndDerivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mention, that in this case we compute the __MSE__ and __MAE__ for vector __y__. In the reference implementation we are averaging the error along the __y__ dimentionality as well.\n",
    "\n",
    "E.g. for residuals vector $[1., 1., 1., 1.]$ the averaged error value will be $\\frac{1}{4}(1. + 1. + 1. + 1.)$ \n",
    "\n",
    "This may be needed to get the desired mutliplier for loss functions derivatives. You also can refer to the `.mse` method implementation, which is already available in the `loss_and_derivatives.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "71VCxUwHGE2L"
   },
   "outputs": [],
   "source": [
    "w = np.array([1., 1.])\n",
    "x_n, y_n = feature_matrix, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([[1, 2 , 3], [4, 5, 6]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sMN81aYyGE2T"
   },
   "source": [
    "Here come several asserts to check yourself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KKUYnPWuGE2V"
   },
   "outputs": [],
   "source": [
    "w = np.array([1., 1.])\n",
    "x_n, y_n = feature_matrix, targets\n",
    "\n",
    "# Repeating data to make everything multi-dimentional\n",
    "w = np.vstack([w[None, :] + 0.27, w[None, :] + 0.22, w[None, :] + 0.45, w[None, :] + 0.1]).T\n",
    "y_n = np.hstack([y_n[:, None], 2*y_n[:, None], 3*y_n[:, None], 4*y_n[:, None]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29766.06109515339\n"
     ]
    }
   ],
   "source": [
    "print(LossAndDerivatives.mse_derivative(x_n, y_n, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1624"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_n.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.32890068, 12.88731311, 18.82128365, 23.97731238],\n",
       "       [ 9.55674399, 17.05397661, 24.98807528, 32.01723714]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LossAndDerivatives.mse_derivative(x_n, y_n, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((406, 2), (406, 4))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_n.shape, y_n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 477
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1344,
     "status": "error",
     "timestamp": 1582397124081,
     "user": {
      "displayName": "Victor Yacovlev",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDahDnBQR6_kQQX4xt7llKTI0xt2Z802bvVR4MrqA=s64",
      "userId": "11689260236152306260"
     },
     "user_tz": -180
    },
    "id": "UtkO4hWYGE2c",
    "outputId": "cb0b99a8-2db4-4873-dfd8-741b52db29f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE derivative:\n",
      "[[ 7.32890068 12.88731311 18.82128365 23.97731238]\n",
      " [ 9.55674399 17.05397661 24.98807528 32.01723714]] \n",
      "\n",
      "L2 reg derivative:\n",
      "[[2.54 2.44 2.9  2.2 ]\n",
      " [2.54 2.44 2.9  2.2 ]]\n"
     ]
    }
   ],
   "source": [
    "reference_mse_derivative = np.array([\n",
    "    [ 7.32890068, 12.88731311, 18.82128365, 23.97731238],\n",
    "    [ 9.55674399, 17.05397661, 24.98807528, 32.01723714]\n",
    "])\n",
    "reference_l2_reg_derivative = np.array([\n",
    "    [2.54, 2.44, 2.9 , 2.2 ],\n",
    "    [2.54, 2.44, 2.9 , 2.2 ]\n",
    "])\n",
    "\n",
    "assert np.allclose(\n",
    "    reference_mse_derivative,\n",
    "    LossAndDerivatives.mse_derivative(x_n, y_n, w), rtol=1e-3\n",
    "), 'Something wrong with MSE derivative'\n",
    "\n",
    "assert np.allclose(\n",
    "    reference_l2_reg_derivative,\n",
    "    LossAndDerivatives.l2_reg_derivative(w), rtol=1e-3\n",
    "), 'Something wrong with L2 reg derivative'\n",
    "\n",
    "print(\n",
    "    'MSE derivative:\\n{} \\n\\nL2 reg derivative:\\n{}'.format(\n",
    "        LossAndDerivatives.mse_derivative(x_n, y_n, w),\n",
    "        LossAndDerivatives.l2_reg_derivative(w))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19708867, 0.19621798, 0.19621798, 0.19572906],\n",
       "       [0.25574138, 0.25524507, 0.25524507, 0.25406404]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LossAndDerivatives.mae_derivative(x_n, y_n, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LossAndDerivatives.l1_reg_derivative(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.08"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.abs(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE derivative:\n",
      "[[0.19708867 0.19621798 0.19621798 0.19572906]\n",
      " [0.25574138 0.25524507 0.25524507 0.25406404]] \n",
      "\n",
      "L1 reg derivative:\n",
      "[[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "reference_mae_derivative = np.array([\n",
    "    [0.19708867, 0.19621798, 0.19621798, 0.19572906],\n",
    "    [0.25574138, 0.25524507, 0.25524507, 0.25406404]\n",
    "])\n",
    "reference_l1_reg_derivative = np.array([\n",
    "    [1., 1., 1., 1.],\n",
    "    [1., 1., 1., 1.]\n",
    "])\n",
    "\n",
    "assert np.allclose(\n",
    "    reference_mae_derivative,\n",
    "    LossAndDerivatives.mae_derivative(x_n, y_n, w), rtol=1e-3\n",
    "), 'Something wrong with MAE derivative'\n",
    "\n",
    "assert np.allclose(\n",
    "    reference_l1_reg_derivative,\n",
    "    LossAndDerivatives.l1_reg_derivative(w), rtol=1e-3\n",
    "), 'Something wrong with L1 reg derivative'\n",
    "\n",
    "print(\n",
    "    'MAE derivative:\\n{} \\n\\nL1 reg derivative:\\n{}'.format(\n",
    "        LossAndDerivatives.mae_derivative(x_n, y_n, w),\n",
    "        LossAndDerivatives.l1_reg_derivative(w))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kJcSPj8UGE20"
   },
   "source": [
    "### Gradient descent on the real data\n",
    "Here comes small loop with gradient descent algorithm. We compute the gradient over the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "On6aSWuIGE21"
   },
   "outputs": [],
   "source": [
    "def get_w_by_grad(X, Y, w_0, loss_mode='mse', reg_mode=None, lr=0.05, n_steps=100, reg_coeff=0.05):\n",
    "    if loss_mode == 'mse':\n",
    "        loss_function = LossAndDerivatives.mse\n",
    "        loss_derivative = LossAndDerivatives.mse_derivative\n",
    "    elif loss_mode == 'mae':\n",
    "        loss_function = LossAndDerivatives.mae\n",
    "        loss_derivative = LossAndDerivatives.mae_derivative\n",
    "    else:\n",
    "        raise ValueError('Unknown loss function. Available loss functions: `mse`, `mae`')\n",
    "    \n",
    "    if reg_mode is None:\n",
    "        reg_function = LossAndDerivatives.no_reg\n",
    "        reg_derivative = LossAndDerivatives.no_reg_derivative # lambda w: np.zeros_like(w)\n",
    "    elif reg_mode == 'l2':\n",
    "        reg_function = LossAndDerivatives.l2_reg\n",
    "        reg_derivative = LossAndDerivatives.l2_reg_derivative\n",
    "    elif reg_mode == 'l1':\n",
    "        reg_function = LossAndDerivatives.l1_reg\n",
    "        reg_derivative = LossAndDerivatives.l1_reg_derivative\n",
    "    else:\n",
    "        raise ValueError('Unknown regularization mode. Available modes: `l1`, `l2`, None')\n",
    "    \n",
    "    \n",
    "    w = w_0.copy()\n",
    "\n",
    "    for i in range(n_steps):\n",
    "        empirical_risk = loss_function(X, Y, w) + reg_coeff * reg_function(w)\n",
    "        gradient = loss_derivative(X, Y, w) + reg_coeff * reg_derivative(w)\n",
    "        gradient_norm = np.linalg.norm(gradient)\n",
    "        if gradient_norm > 5.:\n",
    "            gradient = gradient / gradient_norm * 5.\n",
    "        w -= lr * gradient\n",
    "        \n",
    "        if i % 25 == 0:\n",
    "            print('Step={}, loss={},\\ngradient values={}\\n'.format(i, empirical_risk, gradient))\n",
    "    return w\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A1pyDIyqGE25"
   },
   "outputs": [],
   "source": [
    "# Initial weight matrix\n",
    "w = np.ones((2,1), dtype=float)\n",
    "y_n = targets[:, None] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "erTRQiAFGE29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step=0, loss=231.28353984777308,\n",
      "gradient values=[[3.03360308]\n",
      " [3.97457575]]\n",
      "\n",
      "Step=25, loss=58.512903511682715,\n",
      "gradient values=[[2.28551977]\n",
      " [4.44706638]]\n",
      "\n",
      "Step=50, loss=48.29584498872882,\n",
      "gradient values=[[-0.89558132]\n",
      " [ 0.76425616]]\n",
      "\n",
      "Step=75, loss=47.292783042717005,\n",
      "gradient values=[[-0.48111511]\n",
      " [ 0.40907079]]\n",
      "\n",
      "Step=100, loss=47.004190920297106,\n",
      "gradient values=[[-0.25806412]\n",
      " [ 0.21942022]]\n",
      "\n",
      "Step=125, loss=46.921159712801064,\n",
      "gradient values=[[-0.1384223 ]\n",
      " [ 0.11769421]]\n",
      "\n",
      "Step=150, loss=46.897270698227686,\n",
      "gradient values=[[-0.07424796]\n",
      " [ 0.06312967]]\n",
      "\n",
      "Step=175, loss=46.890397559386315,\n",
      "gradient values=[[-0.03982566]\n",
      " [ 0.03386195]]\n",
      "\n",
      "Step=200, loss=46.88842007984702,\n",
      "gradient values=[[-0.02136197]\n",
      " [ 0.01816312]]\n",
      "\n",
      "Step=225, loss=46.88785113668749,\n",
      "gradient values=[[-0.01145829]\n",
      " [ 0.00974247]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w_grad = get_w_by_grad(x_n, y_n, w, loss_mode='mse', reg_mode='l2', n_steps=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing with `sklearn`\n",
    "Finally, let's compare our model with `sklearn` implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn linear regression implementation delivers MSE = 42.53541245128315\n"
     ]
    }
   ],
   "source": [
    "lr = Ridge(alpha=0.05)\n",
    "lr.fit(x_n, y_n)\n",
    "print('sklearn linear regression implementation delivers MSE = {}'.format(np.mean((lr.predict(x_n) - y_n)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gse1m4nyGE3C"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x_n[:, -1], y_n[:, -1])\n",
    "plt.scatter(x_n[:, -1], x_n.dot(w_grad)[:, -1], color='orange', label='Handwritten linear regression', linewidth=5)\n",
    "plt.scatter(x_n[:, -1], lr.predict(x_n), color='cyan', label='sklearn Ridge')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the solutions may look like a bit different, remember, that handwritten linear regression was unable to fit the bias term, it was equal to $0$ by default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6GgeWdBmGE3H"
   },
   "source": [
    "### Submit your work\n",
    "To submit your work you need to log into Yandex contest (link will be provided later) and upload the `loss_and_derivatives.py` file for the corresponding problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "assignment0_02_linear_regression_and_gradient_descent.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
